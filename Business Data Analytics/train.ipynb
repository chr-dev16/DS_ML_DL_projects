{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity, pairwise_distances\n",
    "from surprise import Reader, Dataset, SVD, SVDpp, NormalPredictor, accuracy\n",
    "from surprise.model_selection import cross_validate, GridSearchCV, KFold\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/preprocessed/movies.csv',index_col=0)\n",
    "movies_reduced = pd.read_csv('../data/preprocessed/movies_reduced.csv',index_col=0)\n",
    "df_ratings = pd.read_csv('../data/preprocessed/df_ratings.csv',index_col=0)\n",
    "train_data = pd.read_csv('../data/preprocessed/train_data.csv',index_col=0)\n",
    "test_data = pd.read_csv('../data/preprocessed/test_data.csv',index_col=0)\n",
    "sim_meta_input = pd.read_csv('../data/preprocessed/sim_meta_input.csv',index_col=0)\n",
    "sim_meta_input_test = pd.read_csv('../data/preprocessed/sim_meta_input_test.csv',index_col=0)\n",
    "sim_meta_input_all = pd.read_csv('../data/preprocessed/sim_meta_input_all.csv',index_col=0)\n",
    "sim_meta_input_test_all = pd.read_csv('../data/preprocessed/sim_meta_input_test_all.csv',index_col=0)\n",
    "svd_meta_input = pd.read_csv('../data/preprocessed/svd_meta_input.csv',index_col=0)\n",
    "svd_meta_input_test = pd.read_csv('../data/preprocessed/svd_meta_input_test.csv',index_col=0)\n",
    "\n",
    "svd = pickle.load(open('svd_model', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Recommendation based on movieID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(movies_reduced['all_in_all'])\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "indices = pd.Series(movies_reduced.index, index=movies_reduced['movieID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movieID):\n",
    "    idx = indices[movieID]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    scores = pd.DataFrame(sim_scores, columns = ['index', 'score'])\n",
    "    movies_with_sim_score = scores.merge(movies_reduced, on ='index' )\n",
    "    movies_with_sim_score.drop(['index', 'all_in_all'], axis = 1, inplace = True)\n",
    "    # Um die Liste zu verkürzen werden nur Filme zurückgegeben mit einem Score über 0.35\n",
    "    return movies_with_sim_score[movies_with_sim_score['score'] > 0.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_low_score(movieID):\n",
    "    idx = indices[movieID]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    scores = pd.DataFrame(sim_scores, columns = ['index', 'score'])\n",
    "    movies_with_sim_score = scores.merge(movies_reduced, on ='index' )\n",
    "    movies_with_sim_score.drop(['index', 'all_in_all'], axis = 1, inplace = True)\n",
    "    # Um die Liste zu verkürzen werden nur Filme zurückgegeben mit einem Score über 0.3\n",
    "    return movies_with_sim_score[movies_with_sim_score['score'] > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_all(movieID):\n",
    "    idx = indices[movieID]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    scores = pd.DataFrame(sim_scores, columns = ['index', 'score'])\n",
    "    movies_with_sim_score = scores.merge(movies_reduced, on ='index' )\n",
    "    movies_with_sim_score.drop(['index', 'all_in_all'], axis = 1, inplace = True)\n",
    "    return movies_with_sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_movies(user_id, movieID):\n",
    "    # Überprüfe ob die imdbID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id'] == user_id], on = 'movieID')\n",
    "        return merged_recommendations\n",
    "    # Ansonsten gebe durchschnittliches rating zurück\n",
    "    else:\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786456</td>\n",
       "      <td>4929</td>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566982</td>\n",
       "      <td>2355</td>\n",
       "      <td>A Bug's Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553041</td>\n",
       "      <td>45517</td>\n",
       "      <td>Cars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.433574</td>\n",
       "      <td>2294</td>\n",
       "      <td>Antz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.400222</td>\n",
       "      <td>32031</td>\n",
       "      <td>I, Robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.395132</td>\n",
       "      <td>588</td>\n",
       "      <td>Aladdin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.394665</td>\n",
       "      <td>673</td>\n",
       "      <td>Space Jam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.387097</td>\n",
       "      <td>4306</td>\n",
       "      <td>Shrek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.387097</td>\n",
       "      <td>47124</td>\n",
       "      <td>The Ant Bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.375183</td>\n",
       "      <td>2092</td>\n",
       "      <td>The Return of Jafar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.375183</td>\n",
       "      <td>3754</td>\n",
       "      <td>The Adventures of Rocky &amp; Bullwinkle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.375183</td>\n",
       "      <td>56152</td>\n",
       "      <td>Enchanted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.366871</td>\n",
       "      <td>1566</td>\n",
       "      <td>Hercules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.366871</td>\n",
       "      <td>1907</td>\n",
       "      <td>Mulan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.366871</td>\n",
       "      <td>3400</td>\n",
       "      <td>We're Back! A Dinosaur's Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.354323</td>\n",
       "      <td>53121</td>\n",
       "      <td>Shrek the Third</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  movieID                                 title\n",
       "0   1.000000     3114                             Toy Story\n",
       "1   0.786456     4929                             Toy Story\n",
       "2   0.566982     2355                          A Bug's Life\n",
       "3   0.553041    45517                                  Cars\n",
       "4   0.433574     2294                                  Antz\n",
       "5   0.400222    32031                              I, Robot\n",
       "6   0.395132      588                               Aladdin\n",
       "7   0.394665      673                             Space Jam\n",
       "8   0.387097     4306                                 Shrek\n",
       "9   0.387097    47124                         The Ant Bully\n",
       "10  0.375183     2092                   The Return of Jafar\n",
       "11  0.375183     3754  The Adventures of Rocky & Bullwinkle\n",
       "12  0.375183    56152                             Enchanted\n",
       "13  0.366871     1566                              Hercules\n",
       "14  0.366871     1907                                 Mulan\n",
       "15  0.366871     3400        We're Back! A Dinosaur's Story\n",
       "16  0.354323    53121                       Shrek the Third"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611347</td>\n",
       "      <td>1196</td>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>1264</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427394</td>\n",
       "      <td>260</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>1264</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416828</td>\n",
       "      <td>2628</td>\n",
       "      <td>Star Wars: Episode I - The Phantom Menace</td>\n",
       "      <td>1264</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.405405</td>\n",
       "      <td>5378</td>\n",
       "      <td>Star Wars: Episode II - Attack of the Clones</td>\n",
       "      <td>1264</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.359447</td>\n",
       "      <td>33493</td>\n",
       "      <td>Star Wars: Episode III - Revenge of the Sith</td>\n",
       "      <td>1264</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  movieID                                           title  user_id  \\\n",
       "0  0.611347     1196  Star Wars: Episode V - The Empire Strikes Back     1264   \n",
       "1  0.427394      260                                       Star Wars     1264   \n",
       "2  0.416828     2628       Star Wars: Episode I - The Phantom Menace     1264   \n",
       "3  0.405405     5378    Star Wars: Episode II - Attack of the Clones     1264   \n",
       "4  0.359447    33493    Star Wars: Episode III - Revenge of the Sith     1264   \n",
       "\n",
       "   rating  \n",
       "0     5.0  \n",
       "1     5.0  \n",
       "2     4.0  \n",
       "3     3.0  \n",
       "4     4.0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_movies(1264, 1210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating prediction - surprise library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization-based algorithm (SVD) https://surprise.readthedocs.io/en/stable/matrix_factorization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "trainset = Dataset.load_from_df(train_data[['user_id', 'movieID', 'rating']], reader)\n",
    "trainset = trainset.build_full_trainset()\n",
    "y_train = train_data[['rating']]\n",
    "x_test = test_data[['user_id', 'movieID']]\n",
    "y_test = test_data[['rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for similar movies of a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alte Methode, wird nicht verwendet\n",
    "def get_relevant_movies(user_id, movieID):\n",
    "    # Überprüfe ob die imdbID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id'] == user_id], on = 'movieID')\n",
    "        return merged_recommendations\n",
    "    # Ansonsten gebe durchschnittliches rating zurück\n",
    "    else:\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movieID</th>\n",
       "      <th>title</th>\n",
       "      <th>imdbID</th>\n",
       "      <th>all_in_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1097</td>\n",
       "      <td>1210</td>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi</td>\n",
       "      <td>86190</td>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi 861...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  movieID                                       title  imdbID  \\\n",
       "1097   1097     1210  Star Wars: Episode VI - Return of the Jedi   86190   \n",
       "\n",
       "                                             all_in_all  \n",
       "1097  Star Wars: Episode VI - Return of the Jedi 861...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_reduced[movies_reduced['movieID']==1210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_movies(1264, 1)\n",
    "#print(get_relevant_movies(1264, 114709))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating(user_id, movieID, no_movieID, no_rel_movies): \n",
    "    weighted_rating = 0\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten gebe durchschnittliches Rating zurück\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean(), no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> durchschnittliches Rating zurückgeben\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean(),no_movieID, no_rel_movies\n",
    "    else:\n",
    "        merged_sum = merged_recommendations['score'].sum()\n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (score / merged_sum)\n",
    "        return weighted_rating, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_three(user_id, movieID, no_movieID, no_rel_movies): \n",
    "    weighted_rating = 0\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten gebe durchschnittliches Rating zurück\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean(), no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> durchschnittliches Rating zurückgeben\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return df_ratings[df_ratings['movieID'] == movieID]['rating'].mean(),no_movieID, no_rel_movies\n",
    "    else:\n",
    "        merged_sum = merged_recommendations['score'].pow(3).sum()\n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (pow(score,3) / merged_sum)\n",
    "        return weighted_rating, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_without_mean(user_id, movieID, no_movieID, no_rel_movies): \n",
    "    weighted_rating = 0\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten gebe -1 zurück\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return -1, no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> -1 zurückgeben\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return -1,no_movieID, no_rel_movies\n",
    "    else:\n",
    "        merged_sum = merged_recommendations['score'].sum()\n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (score / merged_sum)\n",
    "        return weighted_rating, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_with_score(user_id, movieID, no_movieID, no_rel_movies): \n",
    "    weighted_rating = 0\n",
    "    weighted_rating3 = 0\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten gebe durchschnittliches Rating mit Score=0 zurück\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return -1, 0, -1, 0, no_movieID, no_rel_movies\n",
    "    \n",
    "    # falls keine relevanten Filme gefunden wurden -> sim_rating=-1 und score=0 zurückgeben\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return -1, 0, -1, 0, no_movieID, no_rel_movies\n",
    "\n",
    "    else:\n",
    "        merged_sum = merged_recommendations['score'].sum()\n",
    "        merged_sum3 = merged_recommendations['score'].pow(3).sum()\n",
    "        mean_score = merged_recommendations['score'].mean()\n",
    "        mean_score3 = merged_recommendations['score'].pow(3).mean()\n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (score / merged_sum)\n",
    "            weighted_rating3 += rating * (pow(score,3) / merged_sum3)\n",
    "        return weighted_rating, mean_score, weighted_rating3, mean_score3, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rating_all_with_score(user_id, movieID, no_movieID, no_rel_movies): \n",
    "    weighted_rating = 0\n",
    "    weighted_rating3 = 0\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations_all(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten gebe -1 mit Score=0 zurück\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return -1, 0, -1, 0, no_movieID, no_rel_movies\n",
    "\n",
    "  # falls keine relevanten Filme gefunden wurden -> sim_rating=-1 und score=0 zurückgeben\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return -1, 0, -1, 0, no_movieID, no_rel_movies\n",
    "\n",
    "    else:\n",
    "        merged_sum = merged_recommendations['score'].sum()\n",
    "        merged_sum3 = merged_recommendations['score'].pow(3).sum()\n",
    "        mean_score = merged_recommendations['score'].mean()\n",
    "        mean_score3 = merged_recommendations['score'].pow(3).mean()\n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            if merged_sum == 0:\n",
    "                weighted_rating += 0\n",
    "                weighted_rating3 += 0\n",
    "            else:\n",
    "                weighted_rating += rating * (score / merged_sum)\n",
    "                weighted_rating3 += rating * (pow(score,3) / merged_sum3)\n",
    "        return weighted_rating, mean_score, weighted_rating3, mean_score3, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Prediction: (3.384646965752884, 0.06614887630891819, 3.625351320288023, 0.0016639520359948803, 0, 0)\n",
      "SVD Prediction: 3.9989866840483503\n",
      "True Rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "print('Sim Prediction:', calculate_rating_with_score(1264, 1210, 0, 0))\n",
    "print('SVD Prediction:', svd.predict(1264, 1210).est)\n",
    "print('True Rating:', df_ratings.loc[(df_ratings['user_id'] == 1264) & (df_ratings['movieID'] == 1210), 'rating'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rating(svd_est, user_id, movieID, no_movieID, no_rel_movies):\n",
    "\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten SVD-prediction zurückgeben\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> SVD-prediction zurückgeben um sie nicht zu beeinflussen\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "    else:\n",
    "        weighted_rating = 0\n",
    "        merged_sum = merged_recommendations['score'].sum()\n",
    "        mean_similarity = merged_recommendations['score'].mean()\n",
    "            \n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (score / merged_sum)\n",
    "            \n",
    "        result = (svd_est + mean_similarity * weighted_rating) / (1 + mean_similarity)\n",
    "        return result, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def combine_rating_square(svd_est, user_id, movieID, no_movieID, no_rel_movies):\n",
    "\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten SVD-prediction zurückgeben\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> SVD-prediction zurückgeben um sie nicht zu beeinflussen\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "    else:\n",
    "        weighted_rating = 0\n",
    "        merged_sum = merged_recommendations['score'].pow(2).sum()\n",
    "        mean_similarity = merged_recommendations['score'].mean()\n",
    "            \n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (pow(score,2) / merged_sum)\n",
    "            \n",
    "        result = (svd_est + mean_similarity * weighted_rating) / (1 + mean_similarity)\n",
    "        return result, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rating_three(svd_est, user_id, movieID, no_movieID, no_rel_movies):\n",
    "\n",
    "    # Überprüfe ob die movieID überhaupt in der Filmliste ist\n",
    "    if movieID in movies_reduced['movieID'].values:\n",
    "        total_recommendations = get_recommendations(movieID)\n",
    "        merged_recommendations = total_recommendations.merge(df_ratings[df_ratings['user_id']\n",
    "                                                                        == user_id], on = 'movieID')\n",
    "    # Ansonsten SVD-prediction zurückgeben\n",
    "    else:\n",
    "        no_movieID += 1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "\n",
    "    # falls keine relevanten Filme gefunden wurden -> SVD-prediction zurückgeben um sie nicht zu beeinflussen\n",
    "    if merged_recommendations.empty:\n",
    "        no_rel_movies +=1\n",
    "        return svd_est, no_movieID, no_rel_movies\n",
    "    else:\n",
    "        weighted_rating = 0\n",
    "        merged_sum = merged_recommendations['score'].pow(3).sum()\n",
    "        mean_similarity = merged_recommendations['score'].mean()\n",
    "            \n",
    "        for rating, score in zip(merged_recommendations['rating'], merged_recommendations['score']):\n",
    "            weighted_rating += rating * (pow(score,3) / merged_sum)\n",
    "            \n",
    "        result = (svd_est + mean_similarity * weighted_rating) / (1 + mean_similarity)\n",
    "        return result, no_movieID, no_rel_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE nur über Similarity: 0.9167\n",
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 52.23%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_sim = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "    sim_rating, no_movieID, no_rel_movies = calculate_rating_three(user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_sim.append(sim_rating)\n",
    "    \n",
    "print('RMSE nur über Similarity: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_sim))))\n",
    "print('Prozent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/len(test_data))*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/len(test_data))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE nur SVD: 0.7529\n",
      "RMSE hybrides Modell: 0.7521\n",
      "RMSE hybrides Modell quadriert: 0.7514\n",
      "RMSE hybrides Modell hoch 3: 0.7510\n",
      "\n",
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 47.74%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_svd = []\n",
    "y_pred_hybrid = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "y_pred_hybrid2 = []\n",
    "y_pred_hybrid3 = []\n",
    "x=0\n",
    "\n",
    "for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "    pred = svd.predict(user_id, movieID)\n",
    "    combined_rating, no_movieID, no_rel_movies = combine_rating(pred.est, user_id, movieID, no_movieID, no_rel_movies)\n",
    "    combined_rating2, x, x = combine_rating_square(pred.est, user_id, movieID, no_movieID, no_rel_movies)\n",
    "    combined_rating3, x, x = combine_rating_three(pred.est, user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_svd.append(pred.est)\n",
    "    y_pred_hybrid.append(combined_rating)\n",
    "    y_pred_hybrid2.append(combined_rating2)\n",
    "    y_pred_hybrid3.append(combined_rating3)\n",
    "    \n",
    "print('RMSE nur SVD: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_svd))))\n",
    "#print('RMSE nur über Similarity: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_sim))))\n",
    "print('RMSE hybrides Modell: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_hybrid))))\n",
    "print('RMSE hybrides Modell quadriert: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_hybrid2))))\n",
    "print('RMSE hybrides Modell hoch 3: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_hybrid3))))\n",
    "print('\\nProzent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/len(test_data))*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/len(test_data))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>svd_pred</th>\n",
       "      <th>sim_pred</th>\n",
       "      <th>hybrid_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323552</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.519411</td>\n",
       "      <td>3.780894</td>\n",
       "      <td>4.519411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28381</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.080826</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.540413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75610</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.931461</td>\n",
       "      <td>3.637838</td>\n",
       "      <td>3.931461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284365</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.471049</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.471049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333270</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.592356</td>\n",
       "      <td>3.974026</td>\n",
       "      <td>3.592356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380854</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.101078</td>\n",
       "      <td>2.962963</td>\n",
       "      <td>3.101078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185742</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.030143</td>\n",
       "      <td>4.335665</td>\n",
       "      <td>3.379315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430675</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.893375</td>\n",
       "      <td>2.958633</td>\n",
       "      <td>2.893375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728556</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.873509</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.908403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69403</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.347759</td>\n",
       "      <td>3.491069</td>\n",
       "      <td>3.387687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8129 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        true  svd_pred  sim_pred  hybrid_pred\n",
       "323552   5.0  4.519411  3.780894     4.519411\n",
       "28381    3.0  4.080826  3.000000     3.540413\n",
       "75610    4.5  3.931461  3.637838     3.931461\n",
       "284365   1.0  2.471049  2.000000     2.471049\n",
       "333270   4.5  3.592356  3.974026     3.592356\n",
       "...      ...       ...       ...          ...\n",
       "380854   5.0  3.101078  2.962963     3.101078\n",
       "185742   3.5  3.030143  4.335665     3.379315\n",
       "430675   1.0  2.893375  2.958633     2.893375\n",
       "728556   4.5  3.873509  4.000000     3.908403\n",
       "69403    3.0  3.347759  3.491069     3.387687\n",
       "\n",
       "[8129 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'true': y_test['rating'], 'svd_pred': y_pred_svd, 'sim_pred':y_pred_sim, 'hybrid_pred': y_pred_hybrid})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build different Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean rating for each movie\n",
    "temp = pd.DataFrame()\n",
    "temp['rowID'] = (svd_meta_input['user_id'].astype(str) + '000' +\n",
    "                                   svd_meta_input['movieID'].astype(str)).astype(int)\n",
    "mean_rating = df_ratings.groupby(['movieID']).mean()\n",
    "mean_train = svd_meta_input.merge(mean_rating, on = 'movieID')\n",
    "mean_test = test_data.merge(mean_rating, on = 'movieID')\n",
    "mean_train = temp.merge(mean_train, on = 'rowID')\n",
    "mean_test = test_data.merge(mean_test, on = 'rowID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD_Prediction, Sim_prediction (missing movies with -1), Sim_score, Mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_default_score_mean = {'svd_prediction': svd_meta_input['predicted_rating'], \n",
    "                                'similarity_rating': sim_meta_input['sim_pred3'], \n",
    "                                 'score_train': sim_meta_input['sim_score'], \n",
    "                                 'mean_train': mean_train['rating_y']}\n",
    "meta_train_default_score_mean = pd.DataFrame(meta_train_default_score_mean)\n",
    "meta_test_default_score_mean = {'svd_prediction_test': svd_meta_input_test['0'], \n",
    "                                'similarity_rating_test': sim_meta_input_test['sim_pred3'], \n",
    "                                'score_test': sim_meta_input_test['sim_score'],\n",
    "                               'mean_test': mean_test['rating_y']}\n",
    "meta_test_default_score_mean = pd.DataFrame(meta_test_default_score_mean)\n",
    "\n",
    "#meta_train_default_score_mean.to_csv('../data/preprocessed/meta_train_default_score_mean.csv')\n",
    "#meta_test_default_score_mean.to_csv('../data/preprocessed/meta_test_default_score_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Meta Model 1 with Nearest Neighbor: 0.7428\n"
     ]
    }
   ],
   "source": [
    "kn = KNeighborsRegressor(n_neighbors = 765)\n",
    "kn.fit(meta_train_default_score_mean, y_train)\n",
    "y_pred_kn = kn.predict(meta_test_default_score_mean)\n",
    "print('RMSE on Meta Model 1 with Nearest Neighbor: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_kn))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD_Prediction, Sim_prediction (missing movies with SVD_Prediction), Mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_svd_mean = meta_train_default_score_mean.copy()\n",
    "meta_test_svd_mean = meta_test_default_score_mean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for rating, user_id, movieID in zip(meta_train_svd_mean['similarity_rating'], \n",
    "                                    svd_meta_input['user_id'], svd_meta_input['movieID']):\n",
    "    if rating == -1:\n",
    "        pred = svd.predict(user_id, movieID)\n",
    "        meta_train_svd_mean.at[index, 'similarity_rating'] = pred.est\n",
    "    index += 1\n",
    "meta_train_svd_mean.drop(['score_train'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for rating, user_id, movieID in zip(meta_test_svd_mean['similarity_rating_test'], \n",
    "                     \n",
    "                                    test_data['user_id'], test_data['movieID']):\n",
    "    if rating == -1:\n",
    "        pred = svd.predict(user_id, movieID)\n",
    "        meta_test_svd_mean.at[index, 'similarity_rating_test'] = pred.est\n",
    "    index += 1\n",
    "meta_test_svd_mean.drop(['score_test'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Meta Model 2 with Nearest Neighbor: 0.7573\n"
     ]
    }
   ],
   "source": [
    "kn2 = KNeighborsRegressor(n_neighbors = 765)\n",
    "kn2.fit(meta_train_svd_mean, y_train)\n",
    "y_pred_kn2 = kn2.predict(meta_test_svd_mean)\n",
    "print('RMSE on Meta Model 2 with Nearest Neighbor: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_kn2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_svd_mean.to_csv(\n",
    "    '../data/preprocessed/meta_train_svd_mean.csv')\n",
    "meta_test_svd_mean.to_csv(\n",
    "    '../data/preprocessed/meta_test_svd_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD_Prediction, Sim_prediction aller Filme, Sim_score, Mean_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_all_score_mean = {'svd_prediction': svd_meta_input['predicted_rating'], \n",
    "                                'similarity_rating': sim_meta_input_all['sim_pred3'], \n",
    "                                 'score_train': sim_meta_input_all['sim_score3'], \n",
    "                                 'mean_train': mean_train['rating_y']}\n",
    "meta_train_all_score_mean = pd.DataFrame(meta_train_all_score_mean)\n",
    "meta_test_all_score_mean = {'svd_prediction_test': svd_meta_input_test['0'], \n",
    "                                'similarity_rating_test': sim_meta_input_test_all['sim_pred3'], \n",
    "                                'score_test': sim_meta_input_test_all['sim_score3'],\n",
    "                               'mean_test': mean_test['rating_y']}\n",
    "meta_test_all_score_mean = pd.DataFrame(meta_test_all_score_mean)\n",
    "\n",
    "#meta_train_all_score_mean.to_csv('../data/preprocessed/meta_train_all_score_mean.csv')\n",
    "#meta_test_all_score_mean.to_csv('../data/preprocessed/meta_test_all_score_mean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = MinMaxScaler(feature_range = (0.5,5))\n",
    "meta_train_all_score_mean['score_train'] = scaler.fit_transform(meta_train_all_score_mean.loc[:,['score_train']])\n",
    "meta_test_all_score_mean['score_test'] = scaler.transform(meta_test_all_score_mean.loc[:,['score_test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svd_prediction</th>\n",
       "      <th>similarity_rating</th>\n",
       "      <th>score_train</th>\n",
       "      <th>mean_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.931927</td>\n",
       "      <td>3.631255</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>4.005611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.058450</td>\n",
       "      <td>4.031102</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>3.759036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.272626</td>\n",
       "      <td>4.317795</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>4.098712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.387400</td>\n",
       "      <td>3.741454</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>3.099467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.344191</td>\n",
       "      <td>3.623161</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>3.860738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804684</th>\n",
       "      <td>2.586866</td>\n",
       "      <td>2.890961</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>3.170431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804685</th>\n",
       "      <td>4.689347</td>\n",
       "      <td>4.214916</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>4.098074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804686</th>\n",
       "      <td>3.532893</td>\n",
       "      <td>4.062191</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>3.471545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804687</th>\n",
       "      <td>3.604540</td>\n",
       "      <td>3.482007</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>3.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804688</th>\n",
       "      <td>4.216633</td>\n",
       "      <td>4.201222</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>3.847257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804689 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        svd_prediction  similarity_rating  score_train  mean_train\n",
       "0             3.931927           3.631255     0.000489    4.005611\n",
       "1             4.058450           4.031102     0.001957    3.759036\n",
       "2             4.272626           4.317795     0.002181    4.098712\n",
       "3             3.387400           3.741454     0.004418    3.099467\n",
       "4             4.344191           3.623161     0.005589    3.860738\n",
       "...                ...                ...          ...         ...\n",
       "804684        2.586866           2.890961     0.000841    3.170431\n",
       "804685        4.689347           4.214916     0.003393    4.098074\n",
       "804686        3.532893           4.062191     0.002198    3.471545\n",
       "804687        3.604540           3.482007     0.001847    3.975000\n",
       "804688        4.216633           4.201222     0.001926    3.847257\n",
       "\n",
       "[804689 rows x 4 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_all_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Meta Model 3 with Nearest Neighbor: 0.7412\n"
     ]
    }
   ],
   "source": [
    "kn3 = KNeighborsRegressor(n_neighbors = 765)\n",
    "kn3.fit(meta_train_all_score_mean, y_train)\n",
    "y_pred_kn3 = kn3.predict(meta_test_all_score_mean)\n",
    "print('RMSE on Meta Model 3 with Nearest Neighbor: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_kn3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(kn3, open('meta_model_7412', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators, 'max_features': max_features,\n",
    "               'max_depth': max_depth, 'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf, 'bootstrap': bootstrap}\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(rf, param_distributions = random_grid, n_iter = 100,\n",
    "                               cv = 3, random_state=42, n_jobs = -1, verbose = 2)\n",
    "rf_random.fit(meta_train_all_score_mean, y_train)\n",
    "y_pred_random = rf_random.predict(meta_test_all_score_mean)\n",
    "print('RMSE on Meta Model with best Random Forest: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_random))))\n",
    "print('Best parameters for Nearest Neighbor:', rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not needed (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hauke/.local/share/virtualenvs/bda-analytics-challenge-ss2020-ujrcQqei/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/hauke/.local/share/virtualenvs/bda-analytics-challenge-ss2020-ujrcQqei/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Get 1% global hold-out set for testing\n",
    "train_data, test_data = train_test_split(df_ratings, test_size=0.01, random_state = 42)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data['rowID'] = (train_data['user_id'].astype(str) + '000' +\n",
    "                                   train_data['movieID'].astype(str)).astype(int)\n",
    "test_data['rowID'] = (test_data['user_id'].astype(str) + '000' +\n",
    "                                   test_data['movieID'].astype(str)).astype(int)\n",
    "\n",
    "#train_data.to_csv('../data/preprocessed/train_data.csv')\n",
    "#test_data.to_csv('../data/preprocessed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE nur SVD: 0.7529\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#svd = SVD()\n",
    "#svd.fit(trainset)\n",
    "y_pred_svd = []\n",
    "\n",
    "for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "    pred = svd.predict(user_id, movieID)\n",
    "    y_pred_svd.append(pred.est)\n",
    "    \n",
    "print('RMSE nur SVD: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_pred_svd))))\n",
    "#pickle.dump(svd, open('svd_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svd = pd.DataFrame(y_pred_svd)\n",
    "y_pred_svd.to_csv('../data/preprocessed/svd_meta_input_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD RMSE on Testdata: 0.7520\n",
      "SVD RMSE on Testdata: 0.7512\n",
      "SVD RMSE on Testdata: 0.7588\n",
      "SVD RMSE on Testdata: 0.7585\n",
      "SVD RMSE on Testdata: 0.7548\n",
      "SVD RMSE on Testdata: 0.7548\n",
      "SVD RMSE on Testdata: 0.7579\n",
      "SVD RMSE on Testdata: 0.7558\n",
      "SVD RMSE on Testdata: 0.7555\n",
      "SVD RMSE on Testdata: 0.7543\n",
      "SVD RMSE on Testdata: 0.7534\n",
      "SVD RMSE on Testdata: 0.7533\n",
      "SVD RMSE on Testdata: 0.7550\n",
      "SVD RMSE on Testdata: 0.7525\n",
      "SVD RMSE on Testdata: 0.7579\n",
      "SVD RMSE on Testdata: 0.7532\n",
      "SVD RMSE on Testdata: 0.7551\n",
      "SVD RMSE on Testdata: 0.7549\n",
      "SVD RMSE on Testdata: 0.7513\n",
      "SVD RMSE on Testdata: 0.7572\n"
     ]
    }
   ],
   "source": [
    "#### Get input for Meta Model\n",
    "kf = KFold(n_splits=20)\n",
    "svd_fold = SVD()\n",
    "y_pred_svd = []\n",
    "user_id_arr = []\n",
    "movieID_arr = []\n",
    "train_data_fold = Dataset.load_from_df(train_data[['user_id', 'movieID', 'rating']], reader)\n",
    "\n",
    "for trainset, testset in kf.split(train_data_fold):\n",
    "    y_test_svd = []\n",
    "    svd_fold.fit(trainset)\n",
    "    predictions_svd = svd_fold.test(testset)\n",
    "    for pred in predictions_svd:\n",
    "        y_pred_svd.append(pred.est)\n",
    "        user_id_arr.append(pred.uid)\n",
    "        movieID_arr.append(pred.iid)\n",
    "    \n",
    "    for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "        pred = svd_fold.predict(user_id, movieID)\n",
    "        y_test_svd.append(pred.est)\n",
    "    print('SVD RMSE on Testdata: {:.4f}'.format(sqrt(mean_squared_error(y_test, y_test_svd))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Sortiere die Predictions anhand der rowID, sprich wieder wie train_data\n",
    "sorting_data = pd.DataFrame({'user_id':user_id_arr, 'movieID':movieID_arr, 'predicted_rating':y_pred_svd})\n",
    "sorting_data['rowID'] = (sorting_data['user_id'].astype(str) + '000' + sorting_data['movieID'].astype(str)).astype(int)\n",
    "sorting_data.drop(['user_id', 'movieID'], axis=1, inplace=True)\n",
    "df_sorted = train_data.merge(sorting_data, on = 'rowID')\n",
    "df_sorted.to_csv('../data/preprocessed/svd_meta_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sim rating and score for train_data and test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fortschritt: 0.62%\n",
      "Fortschritt: 1.24%\n",
      "Fortschritt: 1.86%\n",
      "Fortschritt: 2.49%\n",
      "Fortschritt: 3.11%\n",
      "Fortschritt: 3.73%\n",
      "Fortschritt: 4.35%\n",
      "Fortschritt: 4.97%\n",
      "Fortschritt: 5.59%\n",
      "Fortschritt: 6.21%\n",
      "Fortschritt: 6.83%\n",
      "Fortschritt: 7.46%\n",
      "Fortschritt: 8.08%\n",
      "Fortschritt: 8.70%\n",
      "Fortschritt: 9.32%\n",
      "Fortschritt: 9.94%\n",
      "Fortschritt: 10.56%\n",
      "Fortschritt: 11.18%\n",
      "Fortschritt: 11.81%\n",
      "Fortschritt: 12.43%\n",
      "Fortschritt: 13.05%\n",
      "Fortschritt: 13.67%\n",
      "Fortschritt: 14.29%\n",
      "Fortschritt: 14.91%\n",
      "Fortschritt: 15.53%\n",
      "Fortschritt: 16.16%\n",
      "Fortschritt: 16.78%\n",
      "Fortschritt: 17.40%\n",
      "Fortschritt: 18.02%\n",
      "Fortschritt: 18.64%\n",
      "Fortschritt: 19.26%\n",
      "Fortschritt: 19.88%\n",
      "Fortschritt: 20.50%\n",
      "Fortschritt: 21.13%\n",
      "Fortschritt: 21.75%\n",
      "Fortschritt: 22.37%\n",
      "Fortschritt: 22.99%\n",
      "Fortschritt: 23.61%\n",
      "Fortschritt: 24.23%\n",
      "Fortschritt: 24.85%\n",
      "Fortschritt: 25.48%\n",
      "Fortschritt: 26.10%\n",
      "Fortschritt: 26.72%\n",
      "Fortschritt: 27.34%\n",
      "Fortschritt: 27.96%\n",
      "Fortschritt: 28.58%\n",
      "Fortschritt: 29.20%\n",
      "Fortschritt: 29.83%\n",
      "Fortschritt: 30.45%\n",
      "Fortschritt: 31.07%\n",
      "Fortschritt: 31.69%\n",
      "Fortschritt: 32.31%\n",
      "Fortschritt: 32.93%\n",
      "Fortschritt: 33.55%\n",
      "Fortschritt: 34.17%\n",
      "Fortschritt: 34.80%\n",
      "Fortschritt: 35.42%\n",
      "Fortschritt: 36.04%\n",
      "Fortschritt: 36.66%\n",
      "Fortschritt: 37.28%\n",
      "Fortschritt: 37.90%\n",
      "Fortschritt: 38.52%\n",
      "Fortschritt: 39.15%\n",
      "Fortschritt: 39.77%\n",
      "Fortschritt: 40.39%\n",
      "Fortschritt: 41.01%\n",
      "Fortschritt: 41.63%\n",
      "Fortschritt: 42.25%\n",
      "Fortschritt: 42.87%\n",
      "Fortschritt: 43.50%\n",
      "Fortschritt: 44.12%\n",
      "Fortschritt: 44.74%\n",
      "Fortschritt: 45.36%\n",
      "Fortschritt: 45.98%\n",
      "Fortschritt: 46.60%\n",
      "Fortschritt: 47.22%\n",
      "Fortschritt: 47.84%\n",
      "Fortschritt: 48.47%\n",
      "Fortschritt: 49.09%\n",
      "Fortschritt: 49.71%\n",
      "Fortschritt: 50.33%\n",
      "Fortschritt: 50.95%\n",
      "Fortschritt: 51.57%\n",
      "Fortschritt: 52.19%\n",
      "Fortschritt: 52.82%\n",
      "Fortschritt: 53.44%\n",
      "Fortschritt: 54.06%\n",
      "Fortschritt: 54.68%\n",
      "Fortschritt: 55.30%\n",
      "Fortschritt: 55.92%\n",
      "Fortschritt: 56.54%\n",
      "Fortschritt: 57.16%\n",
      "Fortschritt: 57.79%\n",
      "Fortschritt: 58.41%\n",
      "Fortschritt: 59.03%\n",
      "Fortschritt: 59.65%\n",
      "Fortschritt: 60.27%\n",
      "Fortschritt: 60.89%\n",
      "Fortschritt: 61.51%\n",
      "Fortschritt: 62.14%\n",
      "Fortschritt: 62.76%\n",
      "Fortschritt: 63.38%\n",
      "Fortschritt: 64.00%\n",
      "Fortschritt: 64.62%\n",
      "Fortschritt: 65.24%\n",
      "Fortschritt: 65.86%\n",
      "Fortschritt: 66.49%\n",
      "Fortschritt: 67.11%\n",
      "Fortschritt: 67.73%\n",
      "Fortschritt: 68.35%\n",
      "Fortschritt: 68.97%\n",
      "Fortschritt: 69.59%\n",
      "Fortschritt: 70.21%\n",
      "Fortschritt: 70.83%\n",
      "Fortschritt: 71.46%\n",
      "Fortschritt: 72.08%\n",
      "Fortschritt: 72.70%\n",
      "Fortschritt: 73.32%\n",
      "Fortschritt: 73.94%\n",
      "Fortschritt: 74.56%\n",
      "Fortschritt: 75.18%\n",
      "Fortschritt: 75.81%\n",
      "Fortschritt: 76.43%\n",
      "Fortschritt: 77.05%\n",
      "Fortschritt: 77.67%\n",
      "Fortschritt: 78.29%\n",
      "Fortschritt: 78.91%\n",
      "Fortschritt: 79.53%\n",
      "Fortschritt: 80.16%\n",
      "Fortschritt: 80.78%\n",
      "Fortschritt: 81.40%\n",
      "Fortschritt: 82.02%\n",
      "Fortschritt: 82.64%\n",
      "Fortschritt: 83.26%\n",
      "Fortschritt: 83.88%\n",
      "Fortschritt: 84.50%\n",
      "Fortschritt: 85.13%\n",
      "Fortschritt: 85.75%\n",
      "Fortschritt: 86.37%\n",
      "Fortschritt: 86.99%\n",
      "Fortschritt: 87.61%\n",
      "Fortschritt: 88.23%\n",
      "Fortschritt: 88.85%\n",
      "Fortschritt: 89.48%\n",
      "Fortschritt: 90.10%\n",
      "Fortschritt: 90.72%\n",
      "Fortschritt: 91.34%\n",
      "Fortschritt: 91.96%\n",
      "Fortschritt: 92.58%\n",
      "Fortschritt: 93.20%\n",
      "Fortschritt: 93.83%\n",
      "Fortschritt: 94.45%\n",
      "Fortschritt: 95.07%\n",
      "Fortschritt: 95.69%\n",
      "Fortschritt: 96.31%\n",
      "Fortschritt: 96.93%\n",
      "Fortschritt: 97.55%\n",
      "Fortschritt: 98.17%\n",
      "Fortschritt: 98.80%\n",
      "Fortschritt: 99.42%\n",
      "\n",
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 47.39%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.01%\n"
     ]
    }
   ],
   "source": [
    "y_pred_sim_train_with_score = []\n",
    "y_pred_sim_train_with_score3 = []\n",
    "score_arr = []\n",
    "score_arr3 = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "data = len(train_data)\n",
    "index = 0\n",
    "\n",
    "for user_id, movieID in zip(train_data['user_id'], train_data['movieID']):\n",
    "    sim_rating, score, sim_rating3, score3, no_movieID, no_rel_movies = calculate_rating_with_score(user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_sim_train_with_score.append(sim_rating)\n",
    "    y_pred_sim_train_with_score3.append(sim_rating3)\n",
    "    score_arr.append(score)\n",
    "    score_arr3.append(score3)\n",
    "    index += 1\n",
    "    if index%5000 == 0:\n",
    "        print('Fortschritt: {:.2f}%'.format((index/data)*100))\n",
    "\n",
    "print('\\nProzent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/data)*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_meta_input = {'sim_pred': y_pred_sim_train_with_score, 'sim_pred3': y_pred_sim_train_with_score3,\n",
    "                 'sim_score': score_arr, 'sim_score3': score_arr3}\n",
    "sim_meta_input = pd.DataFrame(sim_meta_input)\n",
    "#sim_meta_input.to_csv('../data/preprocessed/sim_meta_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 47.74%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_sim_test_with_score = []\n",
    "y_pred_sim_test_with_score3 = []\n",
    "score_arr_test = []\n",
    "score_arr3_test = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "\n",
    "for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "    sim_rating, score, sim_rating3, score3, no_movieID, no_rel_movies = calculate_rating_with_score(user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_sim_test_with_score.append(sim_rating)\n",
    "    y_pred_sim_test_with_score3.append(sim_rating3)\n",
    "    score_arr_test.append(score)\n",
    "    score_arr3_test.append(score3)\n",
    "    \n",
    "print('Prozent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/len(test_data))*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/len(test_data))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_meta_input_test = {'sim_pred': y_pred_sim_test_with_score, 'sim_pred3': y_pred_sim_test_with_score3,\n",
    "                 'sim_score': score_arr_test, 'sim_score3': score_arr3_test}\n",
    "sim_meta_input_test = pd.DataFrame(sim_meta_input_test)\n",
    "#sim_meta_input_test.to_csv('../data/preprocessed/sim_meta_input_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sim rating and score for train_data and test_data for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fortschritt: 0.62%\n",
      "Fortschritt: 1.24%\n",
      "Fortschritt: 1.86%\n",
      "Fortschritt: 2.49%\n",
      "Fortschritt: 3.11%\n",
      "Fortschritt: 3.73%\n",
      "Fortschritt: 4.35%\n",
      "Fortschritt: 4.97%\n",
      "Fortschritt: 5.59%\n",
      "Fortschritt: 6.21%\n",
      "Fortschritt: 6.83%\n",
      "Fortschritt: 7.46%\n",
      "Fortschritt: 8.08%\n",
      "Fortschritt: 8.70%\n",
      "Fortschritt: 9.32%\n",
      "Fortschritt: 9.94%\n",
      "Fortschritt: 10.56%\n",
      "Fortschritt: 11.18%\n",
      "Fortschritt: 11.81%\n",
      "Fortschritt: 12.43%\n",
      "Fortschritt: 13.05%\n",
      "Fortschritt: 13.67%\n",
      "Fortschritt: 14.29%\n",
      "Fortschritt: 14.91%\n",
      "Fortschritt: 15.53%\n",
      "Fortschritt: 16.16%\n",
      "Fortschritt: 16.78%\n",
      "Fortschritt: 17.40%\n",
      "Fortschritt: 18.02%\n",
      "Fortschritt: 18.64%\n",
      "Fortschritt: 19.26%\n",
      "Fortschritt: 19.88%\n",
      "Fortschritt: 20.50%\n",
      "Fortschritt: 21.13%\n",
      "Fortschritt: 21.75%\n",
      "Fortschritt: 22.37%\n",
      "Fortschritt: 22.99%\n",
      "Fortschritt: 23.61%\n",
      "Fortschritt: 24.23%\n",
      "Fortschritt: 24.85%\n",
      "Fortschritt: 25.48%\n",
      "Fortschritt: 26.10%\n",
      "Fortschritt: 26.72%\n",
      "Fortschritt: 27.34%\n",
      "Fortschritt: 27.96%\n",
      "Fortschritt: 28.58%\n",
      "Fortschritt: 29.20%\n",
      "Fortschritt: 29.83%\n",
      "Fortschritt: 30.45%\n",
      "Fortschritt: 31.07%\n",
      "Fortschritt: 31.69%\n",
      "Fortschritt: 32.31%\n",
      "Fortschritt: 32.93%\n",
      "Fortschritt: 33.55%\n",
      "Fortschritt: 34.17%\n",
      "Fortschritt: 34.80%\n",
      "Fortschritt: 35.42%\n",
      "Fortschritt: 36.04%\n",
      "Fortschritt: 36.66%\n",
      "Fortschritt: 37.28%\n",
      "Fortschritt: 37.90%\n",
      "Fortschritt: 38.52%\n",
      "Fortschritt: 39.15%\n",
      "Fortschritt: 39.77%\n",
      "Fortschritt: 40.39%\n",
      "Fortschritt: 41.01%\n",
      "Fortschritt: 41.63%\n",
      "Fortschritt: 42.25%\n",
      "Fortschritt: 42.87%\n",
      "Fortschritt: 43.50%\n",
      "Fortschritt: 44.12%\n",
      "Fortschritt: 44.74%\n",
      "Fortschritt: 45.36%\n",
      "Fortschritt: 45.98%\n",
      "Fortschritt: 46.60%\n",
      "Fortschritt: 47.22%\n",
      "Fortschritt: 47.84%\n",
      "Fortschritt: 48.47%\n",
      "Fortschritt: 49.09%\n",
      "Fortschritt: 49.71%\n",
      "Fortschritt: 50.33%\n",
      "Fortschritt: 50.95%\n",
      "Fortschritt: 51.57%\n",
      "Fortschritt: 52.19%\n",
      "Fortschritt: 52.82%\n",
      "Fortschritt: 53.44%\n",
      "Fortschritt: 54.06%\n",
      "Fortschritt: 54.68%\n",
      "Fortschritt: 55.30%\n",
      "Fortschritt: 55.92%\n",
      "Fortschritt: 56.54%\n",
      "Fortschritt: 57.16%\n",
      "Fortschritt: 57.79%\n",
      "Fortschritt: 58.41%\n",
      "Fortschritt: 59.03%\n",
      "Fortschritt: 59.65%\n",
      "Fortschritt: 60.27%\n",
      "Fortschritt: 60.89%\n",
      "Fortschritt: 61.51%\n",
      "Fortschritt: 62.14%\n",
      "Fortschritt: 62.76%\n",
      "Fortschritt: 63.38%\n",
      "Fortschritt: 64.00%\n",
      "Fortschritt: 64.62%\n",
      "Fortschritt: 65.24%\n",
      "Fortschritt: 65.86%\n",
      "Fortschritt: 66.49%\n",
      "Fortschritt: 67.11%\n",
      "Fortschritt: 67.73%\n",
      "Fortschritt: 68.35%\n",
      "Fortschritt: 68.97%\n",
      "Fortschritt: 69.59%\n",
      "Fortschritt: 70.21%\n",
      "Fortschritt: 70.83%\n",
      "Fortschritt: 71.46%\n",
      "Fortschritt: 72.08%\n",
      "Fortschritt: 72.70%\n",
      "Fortschritt: 73.32%\n",
      "Fortschritt: 73.94%\n",
      "Fortschritt: 74.56%\n",
      "Fortschritt: 75.18%\n",
      "Fortschritt: 75.81%\n",
      "Fortschritt: 76.43%\n",
      "Fortschritt: 77.05%\n",
      "Fortschritt: 77.67%\n",
      "Fortschritt: 78.29%\n",
      "Fortschritt: 78.91%\n",
      "Fortschritt: 79.53%\n",
      "Fortschritt: 80.16%\n",
      "Fortschritt: 80.78%\n",
      "Fortschritt: 81.40%\n",
      "Fortschritt: 82.02%\n",
      "Fortschritt: 82.64%\n",
      "Fortschritt: 83.26%\n",
      "Fortschritt: 83.88%\n",
      "Fortschritt: 84.50%\n",
      "Fortschritt: 85.13%\n",
      "Fortschritt: 85.75%\n",
      "Fortschritt: 86.37%\n",
      "Fortschritt: 86.99%\n",
      "Fortschritt: 87.61%\n",
      "Fortschritt: 88.23%\n",
      "Fortschritt: 88.85%\n",
      "Fortschritt: 89.48%\n",
      "Fortschritt: 90.10%\n",
      "Fortschritt: 90.72%\n",
      "Fortschritt: 91.34%\n",
      "Fortschritt: 91.96%\n",
      "Fortschritt: 92.58%\n",
      "Fortschritt: 93.20%\n",
      "Fortschritt: 93.83%\n",
      "Fortschritt: 94.45%\n",
      "Fortschritt: 95.07%\n",
      "Fortschritt: 95.69%\n",
      "Fortschritt: 96.31%\n",
      "Fortschritt: 96.93%\n",
      "Fortschritt: 97.55%\n",
      "Fortschritt: 98.17%\n",
      "Fortschritt: 98.80%\n",
      "Fortschritt: 99.42%\n",
      "\n",
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 0.00%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.01%\n"
     ]
    }
   ],
   "source": [
    "y_pred_sim_all_train_with_score = []\n",
    "y_pred_sim_all_train_with_score3 = []\n",
    "all_score_arr = []\n",
    "all_score_arr3 = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "data = len(train_data)\n",
    "index = 0\n",
    "\n",
    "for user_id, movieID in zip(train_data['user_id'], train_data['movieID']):\n",
    "    sim_rating, score, sim_rating3, score3, no_movieID, no_rel_movies = calculate_rating_all_with_score(user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_sim_all_train_with_score.append(sim_rating)\n",
    "    y_pred_sim_all_train_with_score3.append(sim_rating3)\n",
    "    all_score_arr.append(score)\n",
    "    all_score_arr3.append(score3)\n",
    "    index += 1\n",
    "    if index%5000 == 0:\n",
    "        print('Fortschritt: {:.2f}%'.format((index/data)*100))\n",
    "\n",
    "print('\\nProzent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/data)*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/data)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_meta_input_all = {'sim_pred': y_pred_sim_all_train_with_score, 'sim_pred3': y_pred_sim_all_train_with_score3,\n",
    "                 'sim_score': all_score_arr, 'sim_score3': all_score_arr3}\n",
    "sim_meta_input_all = pd.DataFrame(sim_meta_input_all)\n",
    "#sim_meta_input_all.to_csv('../data/preprocessed/sim_meta_input_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prozent der Filme für die keine ähnlichen gefunden werden konnten: 0.00%\n",
      "Prozent der Filme für die keine movieID vorhanden ist: 0.00%\n"
     ]
    }
   ],
   "source": [
    "y_pred_sim_test_all_with_score = []\n",
    "y_pred_sim_test_all_with_score3 = []\n",
    "all_score_arr_test = []\n",
    "all_score_arr3_test = []\n",
    "no_movieID = 0\n",
    "no_rel_movies = 0\n",
    "\n",
    "for user_id, movieID in zip(test_data['user_id'], test_data['movieID']):\n",
    "    sim_rating, score, sim_rating3, score3, no_movieID, no_rel_movies = calculate_rating_all_with_score(user_id, movieID, no_movieID, no_rel_movies)\n",
    "    y_pred_sim_test_all_with_score.append(sim_rating)\n",
    "    y_pred_sim_test_all_with_score3.append(sim_rating3)\n",
    "    all_score_arr_test.append(score)\n",
    "    all_score_arr3_test.append(score3)\n",
    "    \n",
    "print('Prozent der Filme für die keine ähnlichen gefunden werden konnten: {:.2f}%'.format((no_rel_movies/len(test_data))*100))\n",
    "print('Prozent der Filme für die keine movieID vorhanden ist: {:.2f}%'.format((no_movieID/len(test_data))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_meta_input_test_all = {'sim_pred': y_pred_sim_test_all_with_score, \n",
    "                           'sim_pred3': y_pred_sim_test_all_with_score3,\n",
    "                 'sim_score': all_score_arr_test, 'sim_score3': all_score_arr3_test}\n",
    "sim_meta_input_test_all = pd.DataFrame(sim_meta_input_test_all)\n",
    "#sim_meta_input_test_all.to_csv('../data/preprocessed/sim_meta_input_test_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bda-analytics-challenge-ss2020-bCwcmXIt",
   "language": "python",
   "name": "bda-analytics-challenge-ss2020-bcwcmxit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "223px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "682px",
    "left": "1545px",
    "right": "20px",
    "top": "120px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
